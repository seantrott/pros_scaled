df_audio$form = factor(df_audio$form)
nrow(df_audio)
table(df_audio$speaker, df_audio$label)
## How many duplicates
df_audio %>%
group_by(hash) %>%
filter(n()>1)
## Get distinct
df_audio = df_audio %>%
distinct(hash, .keep_all = TRUE)
nrow(df_audio)
table(df_audio$speaker, df_audio$label)
df_audio$form = factor(df_audio$form, levels = c("non-conventional", "conventional"))
model_change = lmer(data = df_audio,
overall_change ~ intent2 * form +
(1 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
summary(model_change)
nrow(df_audio)
model_change = lmer(data = filter(df_audio, form == "conventional"),
overall_change ~ intent2 +
(1 | topic) +
(1 | speaker),
REML = FALSE)
summary(model_change)
model_change = lmer(data = df_audio,
f0_slope ~ intent2 * form +
(1 | topic) +
(1 | speaker),
REML = FALSE)
summary(model_change)
setwd("/Users/seantrott/Dropbox/UCSD/Research/IndirectSpeechActs/Prosody/pros_scaled/src/analysis/audio")
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$form = factor(df_audio$form)
nrow(df_audio)
table(df_audio$speaker, df_audio$label)
length(unique(df_audio$ppt_id))
```
## Remove subjects with less than 24 observations
We also exclude participant 16, who was recorded with a lower-quality laptop microphone. (Note that the exclusion does not really affect the primary outcomes reported.)
```{r}
n_obs = df_audio %>%
group_by(ppt_id) %>%
summarise(count = n())
hist(n_obs$count)
complete = n_obs %>%
filter(count == 24)
## print ppt ids with < 24 observations
n_obs %>%
filter(count < 24)
## Select only ppts with 24 observations
df_audio_filtered = df_audio %>%
filter(ppt_id %in% complete$ppt_id)
nrow(df_audio_filtered)
## How many remaining?
length(unique(df_audio_filtered$ppt_id))
## Also remove #16,
df_audio_filtered = df_audio_filtered %>%
filter(ppt_id != 16)
length(unique(df_audio_filtered$ppt_id))
unique(df_audio_filtered$ppt_id)
nrow(df_audio_filtered)
setwd("/Users/seantrott/Dropbox/UCSD/Research/IndirectSpeechActs/Prosody/pros_scaled/src/analysis/audio")
df_audio = read_csv("../../../data/processed/audio/audio_features_final_segment.csv")
df_audio$label = factor(df_audio$intent2)
df_audio$form = factor(df_audio$form)
nrow(df_audio)
table(df_audio$speaker, df_audio$label)
## How many duplicates
df_audio %>%
group_by(hash) %>%
filter(n()>1)
## Get distinct
df_audio = df_audio %>%
distinct(hash, .keep_all = TRUE)
nrow(df_audio)
```
## Descriptive statistics
```{r}
by_intent = df_audio %>%
group_by(form, label) %>%
summarise(mean_change = mean(overall_change),
sd_change = sd(overall_change),
mean_slope = mean(f0_slope),
sd_slope = sd(f0_slope))
by_intent
set.seed(123)
df_audio$index = c(1: nrow(df_audio))
prob_outputs = c()
for (iterating_index in c(1:nrow(df_audio))) {
train = df_audio %>%
filter(index != iterating_index)
test = df_audio %>%
filter(index == iterating_index)
model_core = glm(data = train,
label ~
overall_change * form +
f0_slope * form,
family = binomial())
probabilities = predict(model_core, test, type="response")
prob_outputs[iterating_index] = probabilities
}
df_audio$lr_probs = prob_outputs
df_audio %>%
ggplot(aes(x = lr_probs,
fill = label)) +
geom_density(alpha = .6) +
labs(x = "P(Request)",
title = "Logistic regression predictions by speaker intent",
fill = "Intent") +
theme_minimal()
df_audio$lr_prediction = ifelse(df_audio$lr_probs > 0.5,
"request","non-request")
df_audio$lr_correct = df_audio$lr_prediction == df_audio$label
mean(df_audio$lr_correct)
```
df_audio$form = factor(df_audio$form, levels = c("non-conventional", "conventional"))
model_change = lmer(data = df_audio,
overall_change ~ intent2 * form +
(1 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
summary(model_change)
model_change = lmer(data = df_audio,
f0_slope ~ intent2 * form +
(1 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
summary(model_change)
model_change = lmer(data = df_audio,
f0_slope ~ intent2 * form +
(1 + intent2 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
summary(model_change)
model_change = lmer(data = df_audio,
overall_change ~ intent2 * form +
(1 + intent2 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
summary(model_change)
model_slope = lmer(data = filter(df_audio, form == "conventional"),
f0_slope ~ intent +
(1 | topic) +
(1 | speaker),
REML = FALSE)
summary(model_slope)
model_change = lmer(data = filter(df_audio, form == "conventional"),
overall_change ~ intent2 +
(1 | topic) +
(1 | speaker),
REML = FALSE)
summary(model_change)
df_audio %>%
ggplot(aes(x = form,
y = f0_slope,
color = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
geom_hline(yintercept = 0, linetype = "dotted") +
labs(x = "Form",
y = "F0 Slope",
color = "Intent") +
theme_minimal()
df_audio %>%
ggplot(aes(x = form,
y = overall_change,
color = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
geom_hline(yintercept = 0, linetype = "dotted") +
labs(x = "Form",
y = "Change in F0 (final - initial)",
color = "Intent") +
theme_minimal()
df_audio %>%
ggplot(aes(x = form,
y = overall_change,
color = label,
shape = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
geom_hline(yintercept = 0, linetype = "dotted") +
labs(x = "Form",
y = "Change in F0 (final - initial)",
color = "Intent") +
theme_minimal()
df_audio %>%
ggplot(aes(x = form,
y = overall_change,
color = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
geom_hline(yintercept = 0, linetype = "dotted") +
labs(x = "Form",
y = "Change in F0 (final - initial)",
color = "Intent") +
theme_minimal()
df_audio %>%
ggplot(aes(x = form,
y = overall_change,
color = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
geom_hline(yintercept = 0, linetype = "dotted") +
labs(x = "Form",
y = "Change in F0 (final - initial)",
color = "Intent") +
theme_minimal()
df_audio %>%
ggplot(aes(x = form,
y = f0_slope,
color = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
geom_hline(yintercept = 0, linetype = "dotted") +
labs(x = "Form",
y = "F0 Slope",
color = "Intent") +
theme_minimal()
df_audio$t1
df_audio %>%
mutate(length = t2 - t1) %>%
ggplot(aes(x = form,
y = length,
color = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
geom_hline(yintercept = 0, linetype = "dotted") +
labs(x = "Form",
y = "Change in F0 (final - initial)",
color = "Intent") +
theme_minimal()
df_audio %>%
mutate(length = t2 - t1) %>%
ggplot(aes(x = form,
y = length,
color = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
labs(x = "Form",
y = "Change in F0 (final - initial)",
color = "Intent") +
theme_minimal()
df_audio$form = factor(df_audio$form, levels = c("non-conventional", "conventional"))
model_change = lmer(data = df_audio,
overall_change ~ intent2 * form +
(1 + intent2 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
model_reduced = lmer(data = df_audio,
overall_change ~ intent2 + form +
(1 + intent2 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
anova(model_change, model_reduced)
summary(model_change)
anova(model_change, model_reduced)
model_slope = lmer(data = df_audio,
f0_slope ~ intent2 * form +
(1 + intent2 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
model_reduced = lmer(data = df_audio,
f0_slope ~ intent2 + form +
(1 + intent2 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
anova(model_slope, model_reduced)
summary(model_slope)
anova(model_slope, model_reduced)
model_change = lmer(data = filter(df_audio, form == "conventional"),
overall_change ~ intent2 +
(1 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
summary(model_change)
model_change = lmer(data = filter(df_audio, form == "conventional"),
overall_change ~ intent2 +
(1 +intent2 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
summary(model_change)
model_change = lmer(data = filter(df_audio, form == "conventional"),
overall_change ~ intent2 +
(1 +intent2 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
summary(model_change)
model_null = lmer(data = filter(df_audio, form == "conventional"),
overall_change ~
(1 +intent2 | topic) +
(1 +intent2 | speaker),
REML = FALSE)
anova(model_change, model_null)
model_change = lmer(data = filter(df_audio, form == "conventional"),
f0_slope ~ intent2 +
(1 +intent2 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
model_slope = lmer(data = filter(df_audio, form == "conventional"),
f0_slope ~ intent2 +
(1 +intent2 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
model_null = lmer(data = filter(df_audio, form == "conventional"),
f0_slope ~
(1 +intent2 | topic) +
(1 +intent2 | speaker),
REML = FALSE)
anova(model_slope, model_null)
summary(model_slope)
model_change = lmer(data = filter(df_audio, form == "non-conventional"),
overall_change ~ intent2 +
(1 +intent2 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
model_null = lmer(data = filter(df_audio, form == "non-conventional"),
overall_change ~
(1 +intent2 | topic) +
(1 +intent2 | speaker),
REML = FALSE)
anova(model_change, model_null)
summary(model_change)
model_slope = lmer(data = filter(df_audio, form == "non-conventional"),
f0_slope ~ intent2 +
(1 +intent2 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
model_null = lmer(data = filter(df_audio, form == "non-conventional"),
f0_slope ~
(1 +intent2 | topic) +
(1 +intent2 | speaker),
REML = FALSE)
anova(model_slope, model_null)
summary(model_slope)
df_audio %>%
ggplot(aes(x = form,
y = overall_change,
color = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
geom_hline(yintercept = 0, linetype = "dotted") +
labs(x = "Form",
y = "Change in F0 (final - initial)",
color = "Intent") +
theme_minimal()
ggsave("../../../Figures/supplementary_overall_change.png", dpi = 300)
df_audio$form = factor(df_audio$form, levels = c("non-conventional", "conventional"))
model_change = lmer(data = df_audio,
overall_change ~ intent2 * form +
(1 + intent2 | topic) +
(1 + intent2 | speaker),
control=lmerControl(optimizer="bobyqa"),
REML = FALSE)
df_audio$form = factor(df_audio$form, levels = c("non-conventional", "conventional"))
model_change = lmer(data = df_audio,
overall_change ~ intent2 * form +
(1 | topic) +
(1 + intent2 | speaker),
control=lmerControl(optimizer="bobyqa"),
REML = FALSE)
df_audio$form = factor(df_audio$form, levels = c("non-conventional", "conventional"))
model_change = lmer(data = df_audio,
overall_change ~ intent2 * form +
(1 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
model_reduced = lmer(data = df_audio,
overall_change ~ intent2 + form +
(1 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
anova(model_change, model_reduced)
model_slope = lmer(data = df_audio,
f0_slope ~ intent2 * form +
(1 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
model_reduced = lmer(data = df_audio,
f0_slope ~ intent2 + form +
(1 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
anova(model_slope, model_reduced)
summary(model_slope)
table(df_audio$form)
df_audio %>%
ggplot(aes(x = form,
y = overall_change,
color = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
geom_hline(yintercept = 0, linetype = "dotted") +
labs(x = "Form",
y = "Degree of Rise (final - initial)",
color = "Intent") +
theme_minimal()
ggsave("../../../Figures/supplementary_overall_change.png", dpi = 300)
setwd("/Users/seantrott/Dropbox/UCSD/Research/IndirectSpeechActs/Prosody/pros_scaled/src/analysis/audio")
df_audio = read_csv("../../../data/processed/audio/audio_features_final_segment.csv")
df_audio$label = factor(df_audio$intent2)
df_audio$form = factor(df_audio$form)
nrow(df_audio)
table(df_audio$speaker, df_audio$label)
## How many duplicates
df_audio %>%
group_by(hash) %>%
filter(n()>1)
## Get distinct
df_audio = df_audio %>%
distinct(hash, .keep_all = TRUE)
nrow(df_audio)
df_audio %>%
ggplot(aes(x = form,
y = overall_change,
color = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
geom_hline(yintercept = 0, linetype = "dotted") +
labs(x = "Form",
y = "Degree of Rise (final - initial)",
color = "Intent") +
theme_minimal()
df_audio$form = factor(df_audio$form, levels = c("non-conventional", "conventional"))
model_change = lmer(data = df_audio,
overall_change ~ intent2 * form +
(1 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
model_reduced = lmer(data = df_audio,
overall_change ~ intent2 + form +
(1 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
anova(model_change, model_reduced)
summary(model_change)
model_slope = lmer(data = df_audio,
f0_slope ~ intent2 * form +
(1 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
model_reduced = lmer(data = df_audio,
f0_slope ~ intent2 + form +
(1 | topic) +
(1 + intent2 | speaker),
REML = FALSE)
anova(model_slope, model_reduced)
summary(model_slope)
ggplot(aes(x = form,
y = overall_change,
color = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
geom_hline(yintercept = 0, linetype = "dotted") +
labs(x = "Form",
y = "Degree of Rise (final - initial)",
color = "Intent") +
theme_minimal()
df_audio %>%
ggplot(aes(x = form,
y = overall_change,
color = label)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
geom_hline(yintercept = 0, linetype = "dotted") +
labs(x = "Form",
y = "Degree of Rise (final - initial)",
color = "Intent") +
theme_minimal()
ggsave("../../../Figures/supplementary_overall_change.png", dpi = 300)
