# Statistical rethinking, chapter 5
library(rethinking)
## Divorce rates
data(WaffleDivorce)
d <- WaffleDivorce
# standardize variables
d$A <- scale( d$MedianAgeMarriage )
d$D <- scale( d$Divorce )
data(WaffleDivorce)
d <- WaffleDivorce
# standardize variables
d$A <- scale( d$MedianAgeMarriage )
d$D <- scale( d$Divorce )
m5.1 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bA * A ,
a ~ dnorm( 0 , 0.2 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
summary(m5.1)
set.seed(10)
prior <- extract.prior( m5.1 )
mu <- link( m5.1 , post=prior , data=list( A=c(-2,2) ) )
plot( NULL , xlim=c(-2,2) , ylim=c(-2,2) )
for ( i in 1:50 )
lines( c(-2,2) , mu[i,] , col=col.alpha("black",0.4) )
A_seq <- seq( from=-3 , to=3.2 , length.out=30 )
mu <- link( m5.1 , data=list(A=A_seq) )
mu.mean <- apply( mu , 2, mean )
mu.PI <- apply( mu , 2 , PI )
plot( D ~ A , data=d , col=rangi2 )
lines( A_seq , mu.mean , lwd=2 )
shade( mu.PI , A_seq )
precise(mu)
precis(mu)
mu]
mu
precis(mu)
precis(m5.1)
## Draing DAGs: "daggity"
library(dagitty)
dag5.1 <- dagitty( "dag { A -> D A -> M M -> D
}")
coordinates(dag5.1) <- list( x=c(A=0,D=1,M=2) , y=c(A=0,D=1,M=0) )
drawdag( dag5.1 )
DMA_dag2 <- dagitty('dag{ D <- A -> M }')
impliedConditionalIndependencies( DMA_dag2 )
impliedConditionalIndependencies(dag5.1)
DMA_dag2 <- dagitty('dag{ D <- A <- M }')
impliedConditionalIndependencies( DMA_dag2 )
drawdag(drawdag)
coordinates(DMA_dag2) <- list( x=c(A=0,D=1,M=2) , y=c(A=0,D=1,M=0) )
drawdag(drawdag)
drawdag( DMA_dag2 )
impliedConditionalIndependencies( DMA_dag2 )
DMA_dag2 <- dagitty('dag{ D <- M -> M }')
drawdag( DMA_dag2 )
impliedConditionalIndependencies( DMA_dag2 )
DMA_dag2 <- dagitty('dag{ D <- M -> A }')
drawdag( DMA_dag2 )
impliedConditionalIndependencies( DMA_dag2 )
DMA_dag2 <- dagitty('dag{ D <- A -> M }')
impliedConditionalIndependencies( DMA_dag2 )
dag_a1 <- dagitty( "dag { context -> RT }")
drawdag( dag_a1 )
dag_a1 <- dagitty( "dag { context distance -> RT }")
drawdag( dag_a1 )
dag_a1 <- dagitty( "dag { same context_distance -> RT }")
drawdag( dag_a1 )
dag_a1 <- dagitty( "dag { AT boundary context -> RT }")
drawdag( dag_a1 )
impliedConditionalIndependencies( dag_a1 )
dag_a1 <- dagitty( "dag { AT SB CNXT -> RT }")
drawdag( dag_a1 )
impliedConditionalIndependencies( dag_a1 )
dag_a2 <- dagitty( "dag { AT CNXT -> RT <- SB }")
drawdag( dag_a2 )
impliedConditionalIndependencies( dag_a2 )
dag_a1b <- dagitty( "dag { AT SB -> CNXT -> RT }")
drawdag( dag_a1b )
impliedConditionalIndependencies( dag_a1b )
m5.3 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bM*M + bA*A ,
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
precis( m5.3 )
m5.3 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bM*M + bA*A ,
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
m5.3 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bM*M + bA*A ,
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
d$A <- scale( d$MedianAgeMarriage )
d$M <- scale( d$Marriage )
d$D <- scale( d$Divorce )
m5.3 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bM*M + bA*A ,
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
precis( m5.3 )
plot( coeftab(m5.1,m5.2,m5.3), par=c("bA","bM") )
plot( coeftab(m5.3), par=c("bA","bM") )
coeftab(m5.3)
m5.2 <- quap(
alist(
D ~ dnorm( mu , sigma ) ,
mu <- a + bM * M ,
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
summary(m5.2)
plot( coeftab(m5.1, m5.2, m5.3), par=c("bA","bM") )
N <- 50 # number of simulated States age <- rnorm( N )
# sim A
mar <- rnorm( N , -age ) #
div <- rnorm( N , age )
age <- rnorm( N )
mar <- rnorm( N , -age )
div <- rnorm( N , age )
plot(age, mar)
plot(age, div)
plot(mar, div)
?rnorm
mar <- rnorm( N , -age, sd = 5 )
plot(age, mar)
m5.4 <- quap(
alist(
M ~ dnorm( mu , sigma ) ,
mu <- a + bAM * A ,
a ~ dnorm( 0 , 0.2 ) ,
bAM ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data = d )
mu <- link(m5.4)
mu_mean <- apply( mu , 2 , mean )
mu_resid <- d$M - mu_mean
1- pnorm(68, 70, 3)
pnorm(68, 70, 3, lower.tail=FALSE)
?prnom
?pnorm
67 + .5 * 2.5
67 - .5 * 2.5
pnorm(68.25, 64.5, 2.5) - (1-pnorm(65.275, 64.5, 2.5))
qnorm(.96.2, 70, 3)
qnorm(.962, 70, 3)
qnorm(.962, 0, 1)
qnorm(.984, 64.5,2.5)
pnorm(64, 65,3)
qnorm(.3694, 0,1)
pnorm(64, 70,3)
qnorm(.0227, 0, 1)
qnorm(.0228, 0, 1)
pnorm(64, 70, 3)
.96 - .0228
pnorm(76.29, 64.5, 2.5)
qnorm(.0228, 64.5, 3)
1 - pnorm(63.7, 64.5, 2.5)
?qnorm
pnorm(.9, mean = 50, sd = 5)
qnorm(p = .9, mean = 50, sd = 5)
qnorm(p = .1, mean = 50, sd = 5)
pnorm(q = .9, mean = 531, sd = 104)
qnorm(p = .9, mean = 531, sd = 104)
log(.3) - log(.1)
log(4) - log(2)
log(.6) - log(.2)
log(.6) - log(.15)
# Statistical rethinking, chapter 2
library(tidyverse)
library(rethinking)
dbinom( 6 , size=9 , prob=0.5 )
DATA = 6 ## 6 observed water
NUM_EVENTS = 9 ## 9 events
df_probs = data.frame(hypothesis = seq(0, 1, .01)) ## Various hypotheses for p(W)
df_probs = df_probs %>%
mutate(prior = 1/length(hypothesis),
likelihood = dbinom(DATA , size=NUM_EVENTS, prob=hypothesis)) %>%
mutate(posterior = prior * likelihood)
hist(df_probs$prior)
df_probs %>%
ggplot(aes(x = hypothesis,
y = likelihood)) +
geom_point() +
theme_minimal()
df_probs %>%
ggplot(aes(x = hypothesis,
y = posterior)) +
geom_point() +
theme_minimal()
# Statistical rethinking, chapter 6
library(rethinking)
### Multicollineraity: legs and height
N <- 100 # number of individuals
set.seed(909)
height <- rnorm(N,10,2)
# sim total height of each
leg_prop <- runif(N,0.4,0.5)
# leg as proportion of height
leg_left <- leg_prop*height +
# sim left leg as proportion + error
rnorm( N , 0 , 0.02 )
leg_right <- leg_prop*height + # sim right leg as proportion + error
rnorm( N , 0 , 0.02 )
# combine into data frame
d <- data.frame(height,leg_left,leg_right)
m6.1 <- quap( alist(
height ~ dnorm( mu , sigma ) ,
mu <- a + bl*leg_left + br*leg_right ,
a ~ dnorm( 10 , 100 ) ,
bl ~ dnorm( 2 , 10 ) ,
br ~ dnorm( 2 , 10 ) ,
sigma ~ dexp( 1 )
) , data=d )
precis(m6.1)
plot(precis(m6.1))
post <- extract.samples(m6.1)
plot( bl ~ br , post , col=col.alpha(rangi2,0.1) , pch=16 )
sum_blbr <- post$bl + post$br
dens( sum_blbr , col=rangi2 , lwd=2 , xlab="sum of bl and br" )
N = 50
TARGET = c(5, 5)
df_norm = data.frame(
x = rnorm(mean = 5, sd = 1, n = N),
y = rnorm(mean = 5, sd = 1, n = N)
)
df_norm = data.frame(
x = rnorm(mean = 5, sd = 1, n = N),
y = rnorm(mean = 5, sd = 1, n = N)
)
df_norm
stats::dist
?stats::dist
dist
X1 = c(2, 2)
dist(X1, TARGET)
dist(X1)
dist(c(X1, TARGET))
tx = 5
ty = 5
X1 = c(2, 2)
df_norm = data.frame(
x = rnorm(mean = 5, sd = 1, n = N),
y = rnorm(mean = 5, sd = 1, n = N)
)
df_norm = df_norm %>%
mutate(
ed = sqrt((x - tx)^2 + (y-ty)^2)
)
library(tidyverse)
df_norm = data.frame(
x = rnorm(mean = 5, sd = 1, n = N),
y = rnorm(mean = 5, sd = 1, n = N)
)
df_norm = df_norm %>%
mutate(
ed = sqrt((x - tx)^2 + (y-ty)^2)
)
df_norm %>%
ggplot(aes(x = x,
y = y,
fill = ed)) +
geom_point()
df_norm %>%
ggplot(aes(x = x,
y = y,
color = ed)) +
geom_point()
tx1 = 5
tx2 = 5
df_norm = data.frame(
x1 = rnorm(mean = 5, sd = 1, n = N),
x2 = rnorm(mean = 5, sd = 1, n = N)
)
df_norm = df_norm %>%
mutate(
ed = sqrt((x1 - tx1)^2 + (x2-tx2)^2)
)
df_norm = data.frame(
x1 = rnorm(mean = 5, sd = 1, n = N),
x2 = rnorm(mean = 5, sd = 1, n = N),
y = rnorm(mean = 10, sd = 1, n = N)
)
df_norm = df_norm %>%
mutate(
ed = sqrt((x1 - tx1)^2 + (x2-tx2)^2)
)
m1 = lm(data = df_norm,
y ~ x1 * x2)
summary(m1)
m2 = lm(data = df_norm,
y ~ x1 + x2 + ed)
summary(m2)
1 - pnorm(3)
1 - pnorm(20)
pnorm(54, mean = 50, sd =8) - pnorm(46, mean = 50, sd = 8)
8 / sqrt(4)
pnorm(54, mean = 50, sd =4) - pnorm(46, mean = 50, sd = 4)
8 / sqrt(16)
pnorm(54, mean = 50, sd =2) - pnorm(46, mean = 50, sd = 2)
exp(-2)
-.66*4
-.66*3
exp(-1.98)
-.66*1
exp(-.66)
4 + exp(-.66)
rpoisson
x = c(0, 2, 4, 5, 6)
y = c(180, 200, 150, 165, 210)
cor(x, y)
sp = sum((x - mean(x)) * (y - mean(y)))
sp
sx = sum((x - mean(x))**2)
sx
sy = sum((y = mean(y))**2)
sy
sp / sqrt(sx * sy)
x - mean(x)
dev_x = x - mean(x)
dev_y = y - mean(y)
sp = sum(dev_x * dev_y)
sp
dev_y
y
y = c(180, 200, 150, 165, 210)
cor(x, y)
dev_y = y - mean(y)
dev_y
sp = dev_x * dev_y
sp
sp = sum(sp)
sp
sx = sum(dev_x**2)
sx
sy = sum(dev_y ** 2)
sy
sy * sx
sqrt(sy * sx)
sp / sqrt(sy * sx)
cor(x, y)
x
y
cor(y, x)
cor(x, y)
lm(y ~ x)
h = lm(y ~ x)
h
predict(h)
x
y
k = c(34, 25, 10)
chisq.(k)
chisq.test(k)
?chisq.test
j = c(4, 2, 6, 4, 2, 9, 3, 2, 1, 1, 1, 3, 4, 1, 1, 1)
hist(j)
setwd("/Users/seantrott/Dropbox/UCSD/Research/IndirectSpeechActs/Prosody/pros_scaled/src/analysis/audio")
df_audio = read_csv("../../../data/processed/audio/audio_features_original_stimuli_test.csv")
df_audio$label = fct_recode(df_audio$label,
"Request" = "IR",
"Non-Request" = "Literal")
df_audio$label = factor(df_audio$label, levels = c("Non-Request", "Request"))
setwd("/Users/seantrott/Dropbox/UCSD/Research/IndirectSpeechActs/Prosody/pros_scaled/src/analysis/audio")
df_audio = read_csv("../../../data/processed/audio/audio_features_original_stimuli_test.csv")
df_audio$label = fct_recode(df_audio$label,
"Request" = "IR",
"Non-Request" = "Literal")
df_audio$label = factor(df_audio$label, levels = c("Non-Request", "Request"))
library(tidyverse)
library(forcats)
library(lme4)
```
setwd("/Users/seantrott/Dropbox/UCSD/Research/IndirectSpeechActs/Prosody/pros_scaled/src/analysis/audio")
df_audio = read_csv("../../../data/processed/audio/audio_features_original_stimuli_test.csv")
df_audio$label = fct_recode(df_audio$label,
"Request" = "IR",
"Non-Request" = "Literal")
df_audio$label = factor(df_audio$label, levels = c("Non-Request", "Request"))
df_audio$label = factor(df_audio$label, levels = c("Non-Request", "Request"))
## Z-score
df_audio = df_audio %>%
group_by(speaker) %>%
mutate(mean_f0_z_score = scale(mean_f0),
duration_f0_z_score = scale(duration_f0),
range_f0_z_score = scale(range_f0),
sd_f0_z_score = scale(sd_f0),
slope_f0_z_score = scale(slope_f0),
mean_intensity_z_score = scale(mean_intensity),
sd_intensity_z_score = scale(sd_intensity)
)
df_audio$index = c(1: nrow(df_audio))
prob_outputs = c()
for (iterating_index in c(1:nrow(df_audio))) {
train = df_audio %>%
filter(index != iterating_index)
test = df_audio %>%
filter(index == iterating_index)
model_core = glm(data = train,
label ~ mean_f0_z_score*form + range_f0_z_score*form +
sd_f0_z_score*form + duration_f0_z_score*form +
slope_f0_z_score*form + mean_intensity_z_score*form +
sd_intensity_z_score*form,
family = binomial())
probabilities = predict(model_core, test, type="response")
prob_outputs[iterating_index] = probabilities
}
df_audio$lr_probs = prob_outputs
df_audio$lr_prediction = ifelse(df_audio$lr_probs > 0.5,
"Request","Non-Request")
df_audio %>%
mutate(Intent = label) %>%
ggplot(aes(x = lr_probs,
fill = Intent)) +
geom_density(alpha = .6) +
labs(x = "P(request)") +
theme_minimal()
df_audio$label
setwd("/Users/seantrott/Dropbox/UCSD/Research/IndirectSpeechActs/Prosody/pros_scaled/src/analysis/audio")
df_audio = read_csv("../../../data/processed/audio/audio_features_original_stimuli_test.csv")
df_audio$label = fct_recode(df_audio$label,
"Request" = "IR",
"Non-Request" = "Literal")
df_audio$label = factor(df_audio$label, levels = c("Non-Request", "Request"))
## Z-score
df_audio = df_audio %>%
group_by(speaker) %>%
mutate(mean_f0_z_score = scale(mean_f0),
duration_f0_z_score = scale(duration_f0),
range_f0_z_score = scale(range_f0),
sd_f0_z_score = scale(sd_f0),
slope_f0_z_score = scale(slope_f0),
mean_intensity_z_score = scale(mean_intensity),
sd_intensity_z_score = scale(sd_intensity)
)
df_audio$label
df_audio$intent
etwd("/Users/seantrott/Dropbox/UCSD/Research/IndirectSpeechActs/Prosody/pros_scaled/src/analysis/audio")
df_audio = read_csv("../../../data/processed/audio/audio_features_original_stimuli_test.csv")
factor(a)
factor(df_audio$label)
setwd("/Users/seantrott/Dropbox/UCSD/Research/IndirectSpeechActs/Prosody/pros_scaled/src/analysis/audio")
df_audio = read_csv("../../../data/processed/audio/audio_features_original_stimuli_test.csv")
df_audio$label = fct_recode(df_audio$label,
"Request" = "ir",
"Non-Request" = "literal")
df_audio$label = factor(df_audio$label, levels = c("Non-Request", "Request"))
df_audio$label
df_audio = df_audio %>%
group_by(speaker) %>%
mutate(mean_f0_z_score = scale(mean_f0),
duration_f0_z_score = scale(duration_f0),
range_f0_z_score = scale(range_f0),
sd_f0_z_score = scale(sd_f0),
slope_f0_z_score = scale(slope_f0),
mean_intensity_z_score = scale(mean_intensity),
sd_intensity_z_score = scale(sd_intensity)
)
df_audio$index = c(1: nrow(df_audio))
prob_outputs = c()
for (iterating_index in c(1:nrow(df_audio))) {
train = df_audio %>%
filter(index != iterating_index)
test = df_audio %>%
filter(index == iterating_index)
model_core = glm(data = train,
label ~ mean_f0_z_score*form + range_f0_z_score*form +
sd_f0_z_score*form + duration_f0_z_score*form +
slope_f0_z_score*form + mean_intensity_z_score*form +
sd_intensity_z_score*form,
family = binomial())
probabilities = predict(model_core, test, type="response")
prob_outputs[iterating_index] = probabilities
}
df_audio$lr_probs = prob_outputs
df_audio$lr_prediction = ifelse(df_audio$lr_probs > 0.5,
"Request","Non-Request")
df_audio %>%
mutate(Intent = label) %>%
ggplot(aes(x = lr_probs,
fill = Intent)) +
geom_density(alpha = .6) +
labs(x = "P(request)") +
theme_minimal()
df_audio$lr_correct = df_audio$lr_prediction == df_audio$label
mean(df_audio$lr_correct)
df_audio$form
filter(df_audio, form == "non-conventional")
