duration_f0_z_score = scale(duration_f0),
range_f0_z_score = scale(range_f0),
sd_f0_z_score = scale(sd_f0),
slope_f0_z_score = scale(slope_f0),
mean_intensity_z_score = scale(mean_intensity),
sd_intensity_z_score = scale(sd_intensity)
)
df_audio
mean(df_audio$duration_f0)
103 * 10
103 * 10 / 1000
mean(df_subj$total_seconds) / 60
median(df_subj$total_seconds) / 60
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$condition = fct_recode(df_audio$label,
"Request" = "ir",
"Non-Request" = "literal")
df_audio$speaker = factor(df_audio$speaker)
df_audio = df_audio %>%
group_by(speaker) %>%
mutate(mean_f0_z_score = scale(mean_f0),
duration_f0_z_score = scale(duration_f0),
range_f0_z_score = scale(range_f0),
sd_f0_z_score = scale(sd_f0),
slope_f0_z_score = scale(slope_f0),
mean_intensity_z_score = scale(mean_intensity),
sd_intensity_z_score = scale(sd_intensity)
)
df_audio = df_audio %>%
select(condition, speaker, stimNum, mean_f0_z_score, duration_f0_z_score, range_f0_z_score,
sd_f0_z_score, slope_f0_z_score, mean_intensity_z_score, sd_intensity_z_score) %>%
mutate(speaker = factor(speaker))
nrow(df_audio)
df_processed_audio = df_processed %>%
mutate(speaker = factor(speaker)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
View(df_processed_audio)
# setwd("/Users/seantrott/Dropbox/UCSD/Research/IndirectSpeechActs/Prosody/pros_scaled/src/analysis/behavioral/")
df_processed = read_csv("../../../data/processed/behavioral/pros_scaled_processed.csv")
nrow(df_processed)
length(unique(df_processed$subject))
df_processed$stimNum
df_critical$Intent = factor(fct_recode(df_critical$condition,
"Request" = "request",
"Non-Request" = "statement",
"Non-Request" = "question"), levels = c("Non-Request", "Request"))
## Here, we reset response labels (Request vs. Non-Request)
df_critical$Interpretation = factor(df_critical$response, levels = c("Non-Request", "Request"))
## We also create several more indicator variables for ease of plotting and merging
df_critical = df_critical %>%
mutate(correct = Interpretation == Intent) %>%
mutate(correct_numeric = as.numeric(correct),
## 1 for Request, 0 for Non-Request
response_numeric = as.numeric(Interpretation) - 1) %>%
mutate(topic = tolower(topic))
# For merging with norming data
df_critical$topic = fct_recode(df_critical$topic,
"temperature" = "temp")
```
## Merge with norming data
```{r}
df_normed = read_csv("../../../data/processed/norming/item_means.csv")
df_merged = df_critical %>%
inner_join(df_normed, by = c("form", "topic"))
nrow(df_critical)
nrow(df_merged)
df_normed$topic %in% df_merged$topic
df_processed$topic
```{r}
df_processed_audio = df_processed %>%
mutate(speaker = factor(speaker)) %>%
inner_join(df_audio, on = c("condition", "speaker", "topic"))
nrow(df_processed)
nrow(df_processed_audio)
df_audio$audio
df_audio$topic
df_normed = read_csv("../../../data/processed/norming/item_means.csv")
df_merged = df_critical %>%
inner_join(df_normed, by = c("form", "topic"))
nrow(df_critical)
nrow(df_merged)
df_normed$topic %in% df_merged$topic
df_processed_audio_normed = df_processed %>%
inner_join(df_normed, by = c("form", "topic"))
nrow(df_processed_audio_normed)
nrow(df_processed)
nrow(df_merged)
View(df_processed_audio_normed)
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$condition = fct_recode(df_audio$label,
"Request" = "ir",
"Non-Request" = "literal")
df_audio$speaker = factor(df_audio$speaker)
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$condition = fct_recode(df_audio$label,
"Request" = "ir",
"Non-Request" = "literal")
df_audio$speaker = factor(df_audio$speaker)
df_audio$condition
df_merged$condition
df_audio$label = factor(df_audio$label)
df_audio$speaker = factor(df_audio$speaker)
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
df_processed_audio_normed = df_processed %>%
inner_join(df_normed, by = c("form", "topic"))
nrow(df_processed_audio_normed)
nrow(df_processed)
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$speaker = factor(df_audio$speaker)
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
View(df_processed_audio)
df_processed_audio_normed = df_processed %>%
inner_join(df_normed, by = c("form", "topic"))
nrow(df_processed_audio_normed)
nrow(df_processed)
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$speaker = factor(df_audio$speaker)
df_audio$condition = fct_recode(df_audio$label,
"Request" = "ir",
"Non-Request" = "literal")
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
df_audio$speaker = factor(df_audio$speaker)
df_audio = df_audio %>%
group_by(speaker) %>%
mutate(mean_f0_z_score = scale(mean_f0),
duration_f0_z_score = scale(duration_f0),
range_f0_z_score = scale(range_f0),
sd_f0_z_score = scale(sd_f0),
slope_f0_z_score = scale(slope_f0),
mean_intensity_z_score = scale(mean_intensity),
sd_intensity_z_score = scale(sd_intensity)
)
```
### Merge with behavioral data
```{r}
df_audio = df_audio %>%
select(condition, speaker, stimNum, mean_f0_z_score, duration_f0_z_score, range_f0_z_score,
sd_f0_z_score, slope_f0_z_score, mean_intensity_z_score, sd_intensity_z_score) %>%
mutate(speaker = factor(speaker))
nrow(df_audio)
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$speaker = factor(df_audio$speaker)
df_audio$condition = fct_recode(df_audio$label,
"Request" = "ir",
"Non-Request" = "literal")
df_processed_audio_normed = df_processed %>%
inner_join(df_normed, by = c("form", "topic"))
nrow(df_processed_audio_normed)
nrow(df_processed)
df_audio$speaker
df_processed_audio_normed$speaker
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
# df_audio$speaker = factor(df_audio$speaker)
df_audio$condition = fct_recode(df_audio$label,
"Request" = "ir",
"Non-Request" = "literal")
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
df_processed_audio$duration_f0_z_score
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
# df_audio$speaker = factor(df_audio$speaker)
df_audio$condition = fct_recode(df_audio$label,
"Request" = "ir",
"Non-Request" = "literal")
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$speaker = factor(df_audio$speaker)
df_audio$condition = fct_recode(df_audio$label,
"Request" = "ir",
"Non-Request" = "literal")
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
df_audio$label
df_processed_audio_normed$condition
df_audio$condition
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker),
condition = factor(condition)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$speaker = factor(df_audio$speaker)
df_audio = df_audio %>%
select(-X1)
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker),
condition = factor(condition)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
nrow(df_processed)
df_processed_audio_normed = df_processed %>%
left_join(df_normed, by = c("form", "topic"))
nrow(df_processed_audio_normed)
nrow(df_processed)
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$speaker = factor(df_audio$speaker)
df_audio = df_audio %>%
select(-X1)
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker),
condition = factor(condition)) %>%
left_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
View(df_processed_audio)
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$condition = fct_recode(df_audio$label,
"Request" = "ir",
"Non-Request" = "literal")
df_audio$speaker = factor(df_audio$speaker)
df_audio = df_audio %>%
group_by(speaker) %>%
mutate(mean_f0_z_score = scale(mean_f0),
duration_f0_z_score = scale(duration_f0),
range_f0_z_score = scale(range_f0),
sd_f0_z_score = scale(sd_f0),
slope_f0_z_score = scale(slope_f0),
mean_intensity_z_score = scale(mean_intensity),
sd_intensity_z_score = scale(sd_intensity)
)
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker),
condition = factor(condition)) %>%
left_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
df_processed_audio$duration_f0
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$speaker = factor(df_audio$speaker)
df_audio = df_audio %>%
group_by(speaker) %>%
mutate(mean_f0_z_score = scale(mean_f0),
duration_f0_z_score = scale(duration_f0),
range_f0_z_score = scale(range_f0),
sd_f0_z_score = scale(sd_f0),
slope_f0_z_score = scale(slope_f0),
mean_intensity_z_score = scale(mean_intensity),
sd_intensity_z_score = scale(sd_intensity)
)
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker),
condition = factor(condition)) %>%
left_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
View(df_processed_audio)
df_processed_audio = df_processed_audio_normed %>%
mutate(speaker = factor(speaker),
condition = factor(condition)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_processed)
nrow(df_processed_audio)
nrow(df_processed_audio_normed)
df_subj = df_processed %>%
group_by(subject) %>%
summarise(total_rt = sum(rt, na.rm = TRUE)) %>%
mutate(total_seconds = total_rt / 1000 + 108)
mean(df_subj$total_seconds) / 60
median(df_subj$total_seconds) / 60
setwd("/Users/seantrott/Dropbox/UCSD/Research/IndirectSpeechActs/Prosody/pros_scaled/src/analysis/behavioral/")
df_processed = read_csv("../../../data/processed/behavioral/pros_scaled_processed.csv")
nrow(df_processed)
length(unique(df_processed$subject))
# Filter to just critical stims
df_critical = df_processed %>%
# Critical trials
filter(condition %in% c("statement", "request", "question")) %>%
# The second of each nested trial (i.e., where participant has a response)
filter(!is.na(response))
```
## Checking over data
```{r}
table(df_critical$speaker)
length(unique(df_critical$subject))
```
## Exclusion
We exclude participants who identify as non-native speakers:
```{r}
df_critical = df_critical %>%
filter(Native_Speaker != "No") ## Corrected
nrow(df_critical)
length(unique(df_critical$subject))
```
We also exclude participants with any missing data:
```{r}
# 9 speakers * 12 utterances = 108 items
TOTAL = 108
df_counts = df_critical %>%
group_by(subject) %>%
summarise(count = n())
df_exclude = df_counts %>%
filter(count < TOTAL)
df_critical = df_critical %>%
filter((subject %in% df_exclude$subject) == FALSE)
nrow(df_critical)
length(unique(df_critical$subject))
```
## Additional preprocessing
```{r}
## Here, we reset condition labels (Request vs. Non-Request)
df_critical$Intent = factor(fct_recode(df_critical$condition,
"Request" = "request",
"Non-Request" = "statement",
"Non-Request" = "question"), levels = c("Non-Request", "Request"))
## Here, we reset response labels (Request vs. Non-Request)
df_critical$Interpretation = factor(df_critical$response, levels = c("Non-Request", "Request"))
## We also create several more indicator variables for ease of plotting and merging
df_critical = df_critical %>%
mutate(correct = Interpretation == Intent) %>%
mutate(correct_numeric = as.numeric(correct),
## 1 for Request, 0 for Non-Request
response_numeric = as.numeric(Interpretation) - 1) %>%
mutate(topic = tolower(topic))
# For merging with norming data
df_critical$topic = fct_recode(df_critical$topic,
"temperature" = "temp")
```
## Merge with norming data
```{r}
df_normed = read_csv("../../../data/processed/norming/item_means.csv")
df_merged = df_critical %>%
inner_join(df_normed, by = c("form", "topic"))
nrow(df_critical)
nrow(df_merged)
df_normed$topic %in% df_merged$topic
```
## Merge with acoustic features
### Load acoustic features data
```{r}
df_audio = read_csv("../../../data/processed/audio/audio_features_scaled_stimuli.csv")
df_audio$label = factor(df_audio$label)
df_audio$condition = fct_recode(df_audio$label,
"Request" = "ir",
"Non-Request" = "literal")
df_audio$speaker = factor(df_audio$speaker)
df_audio = df_audio %>%
group_by(speaker) %>%
mutate(mean_f0_z_score = scale(mean_f0),
duration_f0_z_score = scale(duration_f0),
range_f0_z_score = scale(range_f0),
sd_f0_z_score = scale(sd_f0),
slope_f0_z_score = scale(slope_f0),
mean_intensity_z_score = scale(mean_intensity),
sd_intensity_z_score = scale(sd_intensity)
)
```
### Merge with behavioral data
```{r}
df_audio = df_audio %>%
select(condition, speaker, stimNum, mean_f0_z_score, duration_f0_z_score, range_f0_z_score,
sd_f0_z_score, slope_f0_z_score, mean_intensity_z_score, sd_intensity_z_score) %>%
mutate(speaker = factor(speaker))
nrow(df_audio)
df_merged_audio = df_merged %>%
mutate(speaker = factor(speaker)) %>%
inner_join(df_audio, on = c("condition", "speaker", "stimNum"))
nrow(df_merged_audio)
df_merged_audio$form = factor(df_merged_audio$form, levels=c("nonconventional", "conventional"))
df_speaker = read_csv("../../../data/processed/behavioral/speaker_data.csv")
df_speaker = read_csv("../../../data/processed/behavioral/speaker_data.csv") %>%
mutate(speaker = ppt_d) %>%
select(-X1)
df_speaker = read_csv("../../../data/processed/behavioral/speaker_data.csv") %>%
mutate(speaker = ppt_id) %>%
select(-X1)
df_speaker
```{r}
df_speaker = read_csv("../../../data/processed/behavioral/speaker_data.csv") %>%
mutate(speaker = ppt_id,
s_age = Age,
s_gender = Gender) %>%
select(speaker, s_age, s_gender)
df_merged_audio_s = df_merged_audio %>%
inner_join(df_speaker, by = 'speaker')
df_speaker = read_csv("../../../data/processed/behavioral/speaker_data.csv") %>%
mutate(speaker = ppt_id,
s_age = Age,
s_gender = Gender) %>%
select(speaker, s_age, s_gender) %>%
mutate(speaker = factor(speaker))
df_merged_audio_s = df_merged_audio %>%
inner_join(df_speaker, by = 'speaker')
nrow(df_merged_audio_s)
nrow(df_merged_audio)
df_merged_audio_s %>%
ggplot(aes(x = form, y = response_numeric, color = Intent)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
theme_minimal() +
ggtitle("Request interpretations by condition") +
xlab("Condition") +
ylab("Percent choosing 'request'") +
scale_y_continuous(limits = c(0, 1)) +
facet_wrap(~s_gender)
df_merged_audio_s %>%
ggplot(aes(x = form, y = response_numeric, color = Intent)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
theme_minimal() +
ggtitle("Request interpretations by condition") +
xlab("Condition") +
ylab("Percent choosing 'request'") +
scale_y_continuous(limits = c(0, 1)) +
facet_wrap(~s_gender + Gender)
df_merged_audio_s %>%
ggplot(aes(x = form, y = response_numeric, color = Intent)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
theme_minimal() +
ggtitle("Request interpretations by condition") +
xlab("Condition") +
ylab("Percent choosing 'request'") +
scale_y_continuous(limits = c(0, 1)) +
facet_wrap(~s_gender + Gender,
ncol = 2)
df_merged_audio_s %>%
ggplot(aes(x = form, y = response_numeric, color = Intent)) +
stat_summary (fun = function(x){mean(x)},
fun.min = function(x){mean(x) - 2*sd(x)/sqrt(length(x))},
fun.max = function(x){mean(x) + 2*sd(x)/sqrt(length(x))},
geom= 'pointrange',
position=position_dodge(width=0.95)) +
theme_minimal() +
ggtitle("Request interpretations by condition") +
xlab("Condition") +
ylab("Percent choosing 'request'") +
scale_y_continuous(limits = c(0, 1)) +
facet_wrap(~s_gender)
df_merged_audio_s$correct_numeric
model_full = glmer(data=df_merged,
correct_numeric ~ s_gender + form +
(1 + s_gender | topic) +
(1 + s_gender | subject) +
(1 | speaker),
control=glmerControl(optimizer="bobyqa"),
family=binomial())
model_full = glmer(data=df_merged_audio_s,
correct_numeric ~ s_gender + form +
(1 + s_gender | topic) +
(1 + s_gender | subject) +
(1 | speaker),
control=glmerControl(optimizer="bobyqa"),
family=binomial())
summary(model_full)
